{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEYBLojBHsHO7aaHJexB5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-patankar/CPSC597/blob/main/CreditCard_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WbB4mmJ8Rcz",
        "outputId": "458eceec-1263-4d4a-a874-391b25d30edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading creditcardfraud.zip to /content\n",
            " 86% 57.0M/66.0M [00:00<00:00, 101MB/s] \n",
            "100% 66.0M/66.0M [00:00<00:00, 92.2MB/s]\n",
            "Archive:  creditcardfraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mlg-ulb/creditcardfraud\n",
        "!unzip creditcardfraud.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas  as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "df= pd.read_csv('creditcard.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Vzx_0IAE84IL",
        "outputId": "18bd9139-51e6-46fb-ad4f-331649e1a93a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
              "...          ...       ...       ...       ...       ...       ...     ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33521f4c-37b7-4dc9-970a-421b6555c411\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33521f4c-37b7-4dc9-970a-421b6555c411')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33521f4c-37b7-4dc9-970a-421b6555c411 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33521f4c-37b7-4dc9-970a-421b6555c411');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e55861d6-19b4-4db7-8eb9-38d312675b23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e55861d6-19b4-4db7-8eb9-38d312675b23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e55861d6-19b4-4db7-8eb9-38d312675b23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2f1a3413-6bb0-4211-b146-c1950d575c7b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2f1a3413-6bb0-4211-b146-c1950d575c7b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the \"Time\" and \"Amount\" column"
      ],
      "metadata": {
        "id": "K2etAQwqyMvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "new_df = df.copy()\n",
        "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
        "time = new_df['Time']\n",
        "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1OAoX4FxUtv3",
        "outputId": "e8ff17f1-6d91-4d82-c2b2-db276befc590"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0       0.000000  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1       0.000000   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2       0.000006  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3       0.000006  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4       0.000012  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  0.999965 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  0.999971  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  0.999977   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  0.999977  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  1.000000  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  1.783274   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.269825   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  4.983721   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  1.418291   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  0.670579   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.296653   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527  0.038986   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561  0.641096   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.167680   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  2.724796   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27a1cbee-4615-4dcb-8219-6922b34ff62f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>0.999965</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>-0.296653</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>0.999971</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>0.038986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>0.999977</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>0.641096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>0.999977</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>-0.167680</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>2.724796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27a1cbee-4615-4dcb-8219-6922b34ff62f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27a1cbee-4615-4dcb-8219-6922b34ff62f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27a1cbee-4615-4dcb-8219-6922b34ff62f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01c98350-7d03-478d-9c14-7dce006d4e83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01c98350-7d03-478d-9c14-7dce006d4e83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01c98350-7d03-478d-9c14-7dce006d4e83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3c73175f-d94b-40b3-8b21-155d25b086c3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3c73175f-d94b-40b3-8b21-155d25b086c3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffeling the rows\n",
        "new_df = new_df.sample(frac=1, random_state=1)\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NnzprzEH9k0x",
        "outputId": "36238432-7d14-498e-b0d0-1a86eb0b4544"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "169876  0.693938 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
              "127467  0.453377 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
              "137900  0.476770 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
              "21513   0.183556 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
              "134700  0.468326  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "21440   0.183261 -2.986845 -8.663978 -1.910863  0.664058 -3.934875  0.861269   \n",
              "117583  0.432480  0.937083 -0.849673  0.524186 -0.020031 -0.606327  0.692302   \n",
              "73349   0.318852 -1.149963  1.696462  1.637114  2.658991 -0.021502  0.192287   \n",
              "267336  0.941757  1.754554 -0.699398 -0.076332  0.443915 -0.672082  0.389061   \n",
              "128037  0.454743 -0.707635  0.493302  2.648089  1.064807 -0.680271  1.183838   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
              "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
              "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
              "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
              "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "21440   1.647511 -0.480963 -1.546866  ...  1.252092 -0.993085 -2.173147   \n",
              "117583 -0.463724  0.148857  0.785062  ... -0.143322 -0.479981 -0.237902   \n",
              "73349   0.205204  0.588754 -1.187820  ...  0.025147  0.086506 -0.262748   \n",
              "267336 -0.807534  0.202915  0.858635  ...  0.141950  0.358412  0.259748   \n",
              "128037  0.169413  0.074553  1.247988  ... -0.102350  0.323975 -0.172601   \n",
              "\n",
              "             V24       V25       V26       V27       V28     Amount  Class  \n",
              "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180  -0.282401      0  \n",
              "127467  0.401147 -0.261034  0.080621  0.162427  0.059456  -0.279746      0  \n",
              "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516  -0.294977      0  \n",
              "21513   0.009967  0.232829  0.814177  0.098797 -0.004273  -0.084119      0  \n",
              "134700  0.258708  0.552170  0.370701 -0.034255  0.041709  -0.296793      0  \n",
              "...          ...       ...       ...       ...       ...        ...    ...  \n",
              "21440   0.145570 -0.235062 -0.227411 -0.382702  0.404045  32.002515      0  \n",
              "117583 -0.715247  0.251418  0.975406 -0.060168  0.023771   2.086495      0  \n",
              "73349   0.321538  0.341667  0.210343 -0.162047  0.031193  -0.201495      0  \n",
              "267336  0.746839 -0.560808  0.104636 -0.005853 -0.019622   1.017257      0  \n",
              "128037  0.126965 -0.001998 -0.398741 -0.385589 -0.205589   0.500245      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2857812c-eb1d-42c7-b32b-c06d7cc93c56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169876</th>\n",
              "      <td>0.693938</td>\n",
              "      <td>-0.611712</td>\n",
              "      <td>-0.769705</td>\n",
              "      <td>-0.149759</td>\n",
              "      <td>-0.224877</td>\n",
              "      <td>2.028577</td>\n",
              "      <td>-2.019887</td>\n",
              "      <td>0.292491</td>\n",
              "      <td>-0.523020</td>\n",
              "      <td>0.358468</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.075208</td>\n",
              "      <td>0.045536</td>\n",
              "      <td>0.380739</td>\n",
              "      <td>0.023440</td>\n",
              "      <td>-2.220686</td>\n",
              "      <td>-0.201146</td>\n",
              "      <td>0.066501</td>\n",
              "      <td>0.221180</td>\n",
              "      <td>-0.282401</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127467</th>\n",
              "      <td>0.453377</td>\n",
              "      <td>-0.814682</td>\n",
              "      <td>1.319219</td>\n",
              "      <td>1.329415</td>\n",
              "      <td>0.027273</td>\n",
              "      <td>-0.284871</td>\n",
              "      <td>-0.653985</td>\n",
              "      <td>0.321552</td>\n",
              "      <td>0.435975</td>\n",
              "      <td>-0.704298</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.128619</td>\n",
              "      <td>-0.368565</td>\n",
              "      <td>0.090660</td>\n",
              "      <td>0.401147</td>\n",
              "      <td>-0.261034</td>\n",
              "      <td>0.080621</td>\n",
              "      <td>0.162427</td>\n",
              "      <td>0.059456</td>\n",
              "      <td>-0.279746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137900</th>\n",
              "      <td>0.476770</td>\n",
              "      <td>-0.318193</td>\n",
              "      <td>1.118618</td>\n",
              "      <td>0.969864</td>\n",
              "      <td>-0.127052</td>\n",
              "      <td>0.569563</td>\n",
              "      <td>-0.532484</td>\n",
              "      <td>0.706252</td>\n",
              "      <td>-0.064966</td>\n",
              "      <td>-0.463271</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.305402</td>\n",
              "      <td>-0.774704</td>\n",
              "      <td>-0.123884</td>\n",
              "      <td>-0.495687</td>\n",
              "      <td>-0.018148</td>\n",
              "      <td>0.121679</td>\n",
              "      <td>0.249050</td>\n",
              "      <td>0.092516</td>\n",
              "      <td>-0.294977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21513</th>\n",
              "      <td>0.183556</td>\n",
              "      <td>-1.328271</td>\n",
              "      <td>1.018378</td>\n",
              "      <td>1.775426</td>\n",
              "      <td>-1.574193</td>\n",
              "      <td>-0.117696</td>\n",
              "      <td>-0.457733</td>\n",
              "      <td>0.681867</td>\n",
              "      <td>-0.031641</td>\n",
              "      <td>0.383872</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.220815</td>\n",
              "      <td>-0.419013</td>\n",
              "      <td>-0.239197</td>\n",
              "      <td>0.009967</td>\n",
              "      <td>0.232829</td>\n",
              "      <td>0.814177</td>\n",
              "      <td>0.098797</td>\n",
              "      <td>-0.004273</td>\n",
              "      <td>-0.084119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134700</th>\n",
              "      <td>0.468326</td>\n",
              "      <td>1.276712</td>\n",
              "      <td>0.617120</td>\n",
              "      <td>-0.578014</td>\n",
              "      <td>0.879173</td>\n",
              "      <td>0.061706</td>\n",
              "      <td>-1.472002</td>\n",
              "      <td>0.373692</td>\n",
              "      <td>-0.287204</td>\n",
              "      <td>-0.084482</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.160161</td>\n",
              "      <td>-0.430404</td>\n",
              "      <td>-0.076738</td>\n",
              "      <td>0.258708</td>\n",
              "      <td>0.552170</td>\n",
              "      <td>0.370701</td>\n",
              "      <td>-0.034255</td>\n",
              "      <td>0.041709</td>\n",
              "      <td>-0.296793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21440</th>\n",
              "      <td>0.183261</td>\n",
              "      <td>-2.986845</td>\n",
              "      <td>-8.663978</td>\n",
              "      <td>-1.910863</td>\n",
              "      <td>0.664058</td>\n",
              "      <td>-3.934875</td>\n",
              "      <td>0.861269</td>\n",
              "      <td>1.647511</td>\n",
              "      <td>-0.480963</td>\n",
              "      <td>-1.546866</td>\n",
              "      <td>...</td>\n",
              "      <td>1.252092</td>\n",
              "      <td>-0.993085</td>\n",
              "      <td>-2.173147</td>\n",
              "      <td>0.145570</td>\n",
              "      <td>-0.235062</td>\n",
              "      <td>-0.227411</td>\n",
              "      <td>-0.382702</td>\n",
              "      <td>0.404045</td>\n",
              "      <td>32.002515</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117583</th>\n",
              "      <td>0.432480</td>\n",
              "      <td>0.937083</td>\n",
              "      <td>-0.849673</td>\n",
              "      <td>0.524186</td>\n",
              "      <td>-0.020031</td>\n",
              "      <td>-0.606327</td>\n",
              "      <td>0.692302</td>\n",
              "      <td>-0.463724</td>\n",
              "      <td>0.148857</td>\n",
              "      <td>0.785062</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.143322</td>\n",
              "      <td>-0.479981</td>\n",
              "      <td>-0.237902</td>\n",
              "      <td>-0.715247</td>\n",
              "      <td>0.251418</td>\n",
              "      <td>0.975406</td>\n",
              "      <td>-0.060168</td>\n",
              "      <td>0.023771</td>\n",
              "      <td>2.086495</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73349</th>\n",
              "      <td>0.318852</td>\n",
              "      <td>-1.149963</td>\n",
              "      <td>1.696462</td>\n",
              "      <td>1.637114</td>\n",
              "      <td>2.658991</td>\n",
              "      <td>-0.021502</td>\n",
              "      <td>0.192287</td>\n",
              "      <td>0.205204</td>\n",
              "      <td>0.588754</td>\n",
              "      <td>-1.187820</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025147</td>\n",
              "      <td>0.086506</td>\n",
              "      <td>-0.262748</td>\n",
              "      <td>0.321538</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>0.210343</td>\n",
              "      <td>-0.162047</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>-0.201495</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267336</th>\n",
              "      <td>0.941757</td>\n",
              "      <td>1.754554</td>\n",
              "      <td>-0.699398</td>\n",
              "      <td>-0.076332</td>\n",
              "      <td>0.443915</td>\n",
              "      <td>-0.672082</td>\n",
              "      <td>0.389061</td>\n",
              "      <td>-0.807534</td>\n",
              "      <td>0.202915</td>\n",
              "      <td>0.858635</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141950</td>\n",
              "      <td>0.358412</td>\n",
              "      <td>0.259748</td>\n",
              "      <td>0.746839</td>\n",
              "      <td>-0.560808</td>\n",
              "      <td>0.104636</td>\n",
              "      <td>-0.005853</td>\n",
              "      <td>-0.019622</td>\n",
              "      <td>1.017257</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128037</th>\n",
              "      <td>0.454743</td>\n",
              "      <td>-0.707635</td>\n",
              "      <td>0.493302</td>\n",
              "      <td>2.648089</td>\n",
              "      <td>1.064807</td>\n",
              "      <td>-0.680271</td>\n",
              "      <td>1.183838</td>\n",
              "      <td>0.169413</td>\n",
              "      <td>0.074553</td>\n",
              "      <td>1.247988</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102350</td>\n",
              "      <td>0.323975</td>\n",
              "      <td>-0.172601</td>\n",
              "      <td>0.126965</td>\n",
              "      <td>-0.001998</td>\n",
              "      <td>-0.398741</td>\n",
              "      <td>-0.385589</td>\n",
              "      <td>-0.205589</td>\n",
              "      <td>0.500245</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2857812c-eb1d-42c7-b32b-c06d7cc93c56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2857812c-eb1d-42c7-b32b-c06d7cc93c56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2857812c-eb1d-42c7-b32b-c06d7cc93c56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1aec6008-bda2-42bb-9e11-7fc22f148c15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aec6008-bda2-42bb-9e11-7fc22f148c15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1aec6008-bda2-42bb-9e11-7fc22f148c15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d0a95d51-282d-438f-83f9-70497ce75412\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d0a95d51-282d-438f-83f9-70497ce75412 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split the train, test and validation class\n",
        "train, test, val = new_df[:240000], new_df[240000:262000], new_df[262000:]\n",
        "train['Class'].value_counts(), test['Class'].value_counts(), val['Class'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3DgjuEY_Jex",
        "outputId": "5dc1c7f9-7912-4748-aa9c-8012027419b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    239589\n",
              " 1       411\n",
              " Name: Class, dtype: int64,\n",
              " 0    21955\n",
              " 1       45\n",
              " Name: Class, dtype: int64,\n",
              " 0    22771\n",
              " 1       36\n",
              " Name: Class, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#panda dataframe to numpy df\n",
        "train_np, test_np, val_np = train.to_numpy(), test.to_numpy(), val.to_numpy()\n",
        "train_np.shape, test_np.shape, val_np.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-ZQQq6WET2S",
        "outputId": "b0a0c973-3dda-40a3-cd13-f9cb50626fe8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240000, 31), (22000, 31), (22807, 31))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the shapes of the datasets\n",
        "dataset_shapes = {\n",
        "    'Dataset': ['Training', 'Testing', 'Validation'],\n",
        "    'Number of Samples': [train_np.shape[0], test_np.shape[0], val_np.shape[0]],\n",
        "    'Number of Features': [train_np.shape[1], test_np.shape[1], val_np.shape[1]]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df_shapes = pd.DataFrame(dataset_shapes)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_shapes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJma9KTqp99",
        "outputId": "42478f3c-71e6-4f1c-b4ac-67f35d9eca1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Dataset  Number of Samples  Number of Features\n",
            "0    Training             240000                  31\n",
            "1     Testing              22000                  31\n",
            "2  Validation              22807                  31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seperating the features and labels\n",
        "x_train, y_train = train_np[:, :-1], train_np[:, -1]\n",
        "x_test, y_test = test_np[:, :-1], test_np[:, -1]\n",
        "x_val, y_val = val_np[:, :-1], val_np[:, -1]\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fboKpwTUuzF",
        "outputId": "828d449c-0f38-4e59-e06b-ec671d69f81f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((240000, 30), (240000,), (22000, 30), (22000,), (22807, 30), (22807,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning the model with unbalanced dataset."
      ],
      "metadata": {
        "id": "LaGtDBOvzAvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression object\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# train the model on train set\n",
        "lr.fit(x_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(x_val)\n",
        "\n",
        "# print classification report for validation\n",
        "print(classification_report(y_val, predictions, target_names=['Not Fraud','Fraud']))\n",
        "# print(classification_report(y_val,target_names=['Not Fraud', 'Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VdtsHvAbHW",
        "outputId": "fcd5418e-408f-4216-f031-e5fc64f0e913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     22771\n",
            "       Fraud       0.73      0.53      0.61        36\n",
            "\n",
            "    accuracy                           1.00     22807\n",
            "   macro avg       0.87      0.76      0.81     22807\n",
            "weighted avg       1.00      1.00      1.00     22807\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction using test data. (unbalanced dataset)"
      ],
      "metadata": {
        "id": "1_F9pcqt67aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report for test data\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train.ravel())\n",
        "\n",
        "predictions = lr.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud','Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4W7NJ7LCaQD",
        "outputId": "42f829cf-c429-4b8c-9db9-f5cbbb9be139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     21955\n",
            "       Fraud       0.91      0.64      0.75        45\n",
            "\n",
            "    accuracy                           1.00     22000\n",
            "   macro avg       0.95      0.82      0.88     22000\n",
            "weighted avg       1.00      1.00      1.00     22000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "# import SMOTE module from imblearn library\n",
        "# pip install imblearn (if you don't have imblearn in your system)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJdJQpQZDZkT",
        "outputId": "371ea32e-9f7f-485b-eada-1bf140673139"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before OverSampling, counts of label '1': 411\n",
            "Before OverSampling, counts of label '0': 239589 \n",
            "\n",
            "After OverSampling, the shape of train_X: (479178, 30)\n",
            "After OverSampling, the shape of train_y: (479178,) \n",
            "\n",
            "After OverSampling, counts of label '1': 239589\n",
            "After OverSampling, counts of label '0': 239589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the labels and counts before oversampling\n",
        "labels_before = ['Class 0', 'Class 1']\n",
        "counts_before = [sum(y_train == 0), sum(y_train == 1)]\n",
        "\n",
        "# Define the labels and counts after oversampling\n",
        "labels_after = ['Class 0 (Resampled)', 'Class 1 (Resampled)']\n",
        "counts_after = [sum(y_train_res == 0), sum(y_train_res == 1)]\n",
        "\n",
        "# Create subplots for before and after oversampling with smaller figure size\n",
        "fig, axs = plt.subplots(1, 2, figsize=(8, 2.5))  # Adjust the figsize here\n",
        "\n",
        "# Plot before oversampling\n",
        "axs[0].bar(labels_before, counts_before, color=['blue', 'orange'])\n",
        "axs[0].set_title('Class Distribution Before Oversampling')\n",
        "axs[0].set_xlabel('Class')\n",
        "axs[0].set_ylabel('Count')\n",
        "\n",
        "# Plot after oversampling\n",
        "axs[1].bar(labels_after, counts_after, color=['blue', 'orange'])\n",
        "axs[1].set_title('Class Distribution After SMOTE Oversampling')\n",
        "axs[1].set_xlabel('Class')\n",
        "axs[1].set_ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "CqV57pT-sRrZ",
        "outputId": "301d27b7-5482-4440-e375-b2733fafa01c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x250 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traning the model using balanced dataset."
      ],
      "metadata": {
        "id": "CsmqnxcnC1v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#classification after smote\n",
        "lr_smote = LogisticRegression()\n",
        "lr_smote.fit(X_train_res, y_train_res.ravel())\n",
        "predictions = lr_smote.predict(x_test)\n",
        "\n",
        "# print(classification_report(y_test, predictions))\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud','Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIJPQOSaFFxw",
        "outputId": "219cb39c-4911-4daa-f94c-e4ad516ae154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      0.98      0.99     21955\n",
            "       Fraud       0.07      0.91      0.13        45\n",
            "\n",
            "    accuracy                           0.98     22000\n",
            "   macro avg       0.54      0.94      0.56     22000\n",
            "weighted avg       1.00      0.98      0.99     22000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix after smote\n",
        "cm = confusion_matrix(y_test, lr_smote.predict(x_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whh9ZOuiI_lR",
        "outputId": "0d266e0a-294c-4086-ab20-b19e2265e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21386   576]\n",
            " [    3    35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix before smote\n",
        "cm = confusion_matrix(y_test, lr.predict(x_test))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx0Pb2gIKra_",
        "outputId": "3d19aa0d-8f54-47aa-d605-2349fc1c7e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21957     5]\n",
            " [    8    30]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "\n",
        "joblib.dump(lr_smote, 'lr_smote.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Dnoo6sN6bd",
        "outputId": "010b4e64-2d70-4fb5-cfcf-d96d2a2b5834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr_smote.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDrWCip5Pf2V",
        "outputId": "e4efb126-4806-47b4-d195-1532457849ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Assuming 'model' is your trained model\n",
        "# Save the model to a specific path on your Google Drive\n",
        "joblib.dump(lr_smote, '/content/drive/MyDrive/CPSC-597/lr_smote.pkl')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvbBmJ00QIHC",
        "outputId": "1272c5ef-e98a-4216-8d28-c13795724bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/CPSC-597/lr_smote.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "shallow_nn = Sequential()\n",
        "shallow_nn.add(InputLayer((X_train_res.shape[1],)))\n",
        "shallow_nn.add(Dense(2, 'relu'))\n",
        "shallow_nn.add(BatchNormalization())\n",
        "shallow_nn.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "checkpoint = ModelCheckpoint('shallow_nn', save_best_only=True)\n",
        "shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EpXDHjwNvRiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeoZf-rJy2Cr",
        "outputId": "685c73be-59f5-472d-dd02-d1f3982b15cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 2)                 8         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73 (292.00 Byte)\n",
            "Trainable params: 69 (276.00 Byte)\n",
            "Non-trainable params: 4 (16.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_nn.fit(X_train_res, y_train_res, validation_data=(x_val, y_val), epochs=5, callbacks=checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCv701Ipy6mj",
        "outputId": "70194914-9617-408c-f327-f2fb94a4fba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14975/14975 [==============================] - 31s 2ms/step - loss: 0.2040 - accuracy: 0.9267 - val_loss: 0.0991 - val_accuracy: 0.9815\n",
            "Epoch 2/5\n",
            "14975/14975 [==============================] - 35s 2ms/step - loss: 0.1541 - accuracy: 0.9410 - val_loss: 0.0905 - val_accuracy: 0.9825\n",
            "Epoch 3/5\n",
            "14975/14975 [==============================] - 31s 2ms/step - loss: 0.1540 - accuracy: 0.9414 - val_loss: 0.0931 - val_accuracy: 0.9818\n",
            "Epoch 4/5\n",
            "14975/14975 [==============================] - 32s 2ms/step - loss: 0.1539 - accuracy: 0.9416 - val_loss: 0.0951 - val_accuracy: 0.9816\n",
            "Epoch 5/5\n",
            "14975/14975 [==============================] - 33s 2ms/step - loss: 0.1530 - accuracy: 0.9417 - val_loss: 0.0927 - val_accuracy: 0.9818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78613b60aad0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (shallow_nn.predict(x_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions, target_names=['Not Fraud', 'Fraud']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP-ndrY2zmXr",
        "outputId": "645b38ea-b671-44f8-8a77-e3c5f15358fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688/688 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     21962\n",
            "       Fraud       0.77      0.87      0.81        38\n",
            "\n",
            "    accuracy                           1.00     22000\n",
            "   macro avg       0.88      0.93      0.91     22000\n",
            "weighted avg       1.00      1.00      1.00     22000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhDfE3sU4a-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LJEna710KLT",
        "outputId": "5dc280f6-13a4-4393-c47c-2ef5f2da7a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[21952    10]\n",
            " [    5    33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untill this point, SMOTE is giving better accuracy in detecting fraud using linear regression(Fraud       0.06      0.92      0.11).\n",
        "Sequencial neural network has slightly better precision and f1-score, lowering the accuracy of fetecting fraud. But model is significantly good. (0.77      0.87      0.81)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "55mAE1733piZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing autoencoders\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the credit card transaction dataset\n",
        "ae_data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "ae_x = ae_data.drop(\"Class\", axis=1)\n",
        "ae_y = ae_data[\"Class\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(ae_x, ae_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(input_dim, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "# Train the autoencoder on normal transactions\n",
        "model.fit(X_train[y_train == 0], X_train[y_train == 0],\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_test, X_test))\n",
        "\n",
        "# Reconstruct the test data and calculate reconstruction error\n",
        "reconstructed = model.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - reconstructed, 2), axis=1)\n",
        "threshold = np.mean(mse) + 2 * np.std(mse)  # Set threshold as mean + 2*std deviation\n",
        "\n",
        "# Predict fraud based on reconstruction error\n",
        "y_pred = (mse > threshold).astype(int)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xlDQbwu8tAY",
        "outputId": "f0ff7d7d-d364-4b0d-dbe7-87ee9724cc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1777/1777 [==============================] - 5s 2ms/step - loss: 0.6991 - val_loss: 0.6725\n",
            "Epoch 2/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6420 - val_loss: 0.6604\n",
            "Epoch 3/10\n",
            "1777/1777 [==============================] - 6s 3ms/step - loss: 0.6350 - val_loss: 0.6579\n",
            "Epoch 4/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6340 - val_loss: 0.6573\n",
            "Epoch 5/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6335 - val_loss: 0.6570\n",
            "Epoch 6/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6333 - val_loss: 0.6568\n",
            "Epoch 7/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6333 - val_loss: 0.6568\n",
            "Epoch 8/10\n",
            "1777/1777 [==============================] - 5s 3ms/step - loss: 0.6332 - val_loss: 0.6571\n",
            "Epoch 9/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6332 - val_loss: 0.6567\n",
            "Epoch 10/10\n",
            "1777/1777 [==============================] - 4s 2ms/step - loss: 0.6332 - val_loss: 0.6569\n",
            "1781/1781 [==============================] - 2s 1ms/step\n",
            "[[56419   445]\n",
            " [   39    59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56864\n",
            "           1       0.12      0.60      0.20        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.56      0.80      0.60     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing autoencoders\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the credit card transaction dataset\n",
        "# ae_data = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "# ae_x = ae_data.drop(\"Class\", axis=1)\n",
        "# ae_y = ae_data[\"Class\"]\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(ae_x, ae_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_res)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(input_dim, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "# Train the autoencoder on normal transactions\n",
        "model.fit(X_train[y_train_res == 0], X_train[y_train_res == 0],\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_test, X_test))\n",
        "\n",
        "# Reconstruct the test data and calculate reconstruction error\n",
        "reconstructed = model.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - reconstructed, 2), axis=1)\n",
        "threshold = np.mean(mse) + 2 * np.std(mse)  # Set threshold as mean + 2*std deviation\n",
        "\n",
        "# Predict fraud based on reconstruction error\n",
        "y_pred = (mse > threshold).astype(int)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3RgM6p8_wYe",
        "outputId": "76c8172f-88f7-44d4-a1d2-8b564d01b348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1872/1872 [==============================] - 8s 4ms/step - loss: 0.3337 - val_loss: 1.2752\n",
            "Epoch 2/10\n",
            "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3117 - val_loss: 1.2720\n",
            "Epoch 3/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3049 - val_loss: 1.2483\n",
            "Epoch 4/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3022 - val_loss: 1.2485\n",
            "Epoch 5/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3021 - val_loss: 1.2475\n",
            "Epoch 6/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3020 - val_loss: 1.2474\n",
            "Epoch 7/10\n",
            "1872/1872 [==============================] - 6s 3ms/step - loss: 0.3019 - val_loss: 1.2465\n",
            "Epoch 8/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3019 - val_loss: 1.2482\n",
            "Epoch 9/10\n",
            "1872/1872 [==============================] - 4s 2ms/step - loss: 0.3015 - val_loss: 1.2434\n",
            "Epoch 10/10\n",
            "1872/1872 [==============================] - 5s 3ms/step - loss: 0.3014 - val_loss: 1.2422\n",
            "1781/1781 [==============================] - 2s 1ms/step\n",
            "[[56688   176]\n",
            " [   93     5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.03      0.05      0.04        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.51      0.52      0.52     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ]
        }
      ]
    }
  ]
}